{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b9e4a1",
   "metadata": {},
   "source": [
    "# Sentiment Classification Model 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff75b4",
   "metadata": {},
   "source": [
    "Trained on merged dataset (SST-3, DynaSent R1, R2) with neutral reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc6ae4d",
   "metadata": {},
   "source": [
    "### 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24964ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from transformers import (\n",
    "    BertTokenizer, \n",
    "    BertForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support, f1_score\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280cfe62",
   "metadata": {},
   "source": [
    "### 2. Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfbe3899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b052cdd1-d978-47c1-ad7e-2943ab8ddba8",
       "rows": [
        [
         "0",
         "Those 2 drinks are part of the HK culture and has years of history. It is so bad.",
         "negative",
         "dynasent_r2",
         "train"
        ],
        [
         "1",
         "I was told by the repair company that was doing the car repair that fixing the rim was \"impossible\" and to replace it.",
         "negative",
         "dynasent_r1",
         "train"
        ],
        [
         "2",
         "It is there to give them a good time .",
         "neutral",
         "sst_local",
         "train"
        ],
        [
         "3",
         "Like leafing through an album of photos accompanied by the sketchiest of captions .",
         "negative",
         "sst_local",
         "train"
        ],
        [
         "4",
         "Johnny was a talker and liked to have fun.",
         "positive",
         "dynasent_r1",
         "train"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Those 2 drinks are part of the HK culture and ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>dynasent_r2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was told by the repair company that was doin...</td>\n",
       "      <td>negative</td>\n",
       "      <td>dynasent_r1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is there to give them a good time .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sst_local</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Like leafing through an album of photos accomp...</td>\n",
       "      <td>negative</td>\n",
       "      <td>sst_local</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Johnny was a talker and liked to have fun.</td>\n",
       "      <td>positive</td>\n",
       "      <td>dynasent_r1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence     label       source  \\\n",
       "0  Those 2 drinks are part of the HK culture and ...  negative  dynasent_r2   \n",
       "1  I was told by the repair company that was doin...  negative  dynasent_r1   \n",
       "2             It is there to give them a good time .   neutral    sst_local   \n",
       "3  Like leafing through an album of photos accomp...  negative    sst_local   \n",
       "4         Johnny was a talker and liked to have fun.  positive  dynasent_r1   \n",
       "\n",
       "   split  \n",
       "0  train  \n",
       "1  train  \n",
       "2  train  \n",
       "3  train  \n",
       "4  train  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"jbeno/sentiment_merged\")\n",
    "\n",
    "train_ds = dataset[\"train\"]\n",
    "valid_ds = dataset[\"validation\"]\n",
    "test_ds  = dataset[\"test\"]\n",
    "\n",
    "df_train = pd.DataFrame(train_ds)      \n",
    "df_valid = pd.DataFrame(valid_ds)\n",
    "df_test  = pd.DataFrame(test_ds)\n",
    "\n",
    "df_train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed3019a",
   "metadata": {},
   "source": [
    "### 3. Map string labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "df_test[\"label_id\"] = df_test[\"label\"].map(label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faf42de",
   "metadata": {},
   "source": [
    "### 4. Create a Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d118c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        # texts and labels can be lists or pd.Series\n",
    "        self.texts = texts.tolist() if hasattr(texts, \"tolist\") else texts\n",
    "        self.labels = labels.tolist() if hasattr(labels, \"tolist\") else labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee50022",
   "metadata": {},
   "source": [
    "### 5. Instansiate Tokenizer & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_uncased = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "train_ds_uncased = SentimentDataset(df_train[\"sentence\"],   df_train[\"label\"],   tokenizer_uncased)\n",
    "val_ds_uncased   = SentimentDataset(df_valid[\"sentence\"],   df_valid[\"label\"],   tokenizer_uncased)\n",
    "test_ds_uncased  = SentimentDataset(df_test[\"sentence\"],    df_test[\"label\"],    tokenizer_uncased)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767e0e2e",
   "metadata": {},
   "source": [
    "### 6. Initialize Model and Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e6ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args_uncased = TrainingArguments(\n",
    "    output_dir=\"outputs_uncased_8\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"logs_uncased\",\n",
    "    logging_steps=50,\n",
    "    fp16=True if torch.cuda.is_available() else False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91600c86",
   "metadata": {},
   "source": [
    "### 7. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad60ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uncased = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dfd548",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_uncased = Trainer(\n",
    "    model=model_uncased,\n",
    "    args=training_args_uncased,\n",
    "    train_dataset=train_ds_uncased,\n",
    "    eval_dataset=val_ds_uncased\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff73e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training bert-base-uncased model...\")\n",
    "trainer_uncased.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab343ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_uncased = trainer_uncased.predict(test_ds_uncased)\n",
    "pred_labels_uncased = predictions_uncased.predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Build a DataFrame with the true labels + your predictions\n",
    "df_eval = pd.DataFrame({\n",
    "    \"sentence\": df_test[\"sentence\"].tolist(),   # the raw text\n",
    "    \"true_label\":  df_test[\"label\"].tolist(),   # 0/1/2\n",
    "    \"pred_label\":  pred_labels_uncased          # your model’s 0/1/2 outputs\n",
    "})\n",
    "\n",
    "# 2. Compute overall accuracy and macro‑F1\n",
    "acc  = accuracy_score(df_eval[\"true_label\"], df_eval[\"pred_label\"])\n",
    "f1m  = f1_score(df_eval[\"true_label\"], df_eval[\"pred_label\"], average=\"macro\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Macro‑F1 : {f1m:.4f}\\n\")\n",
    "\n",
    "# 3. Full classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(\n",
    "    df_eval[\"true_label\"],\n",
    "    df_eval[\"pred_label\"],\n",
    "    target_names=[\"negative\",\"neutral\",\"positive\"]\n",
    "))\n",
    "\n",
    "# 4. Confusion matrix\n",
    "cm = confusion_matrix(\n",
    "    df_eval[\"true_label\"],\n",
    "    df_eval[\"pred_label\"],\n",
    "    labels=[0,1,2]\n",
    ")\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[\"true_neg\",\"true_neu\",\"true_pos\"],\n",
    "    columns=[\"pred_neg\",\"pred_neu\",\"pred_pos\"]\n",
    ")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "display(cm_df)\n",
    "\n",
    "# 5. (Optional) Save out predictions\n",
    "df_eval.to_csv(\"hf_sentiment_predictions.csv\", index=False)\n",
    "print(\"\\nSaved predictions and true labels to hf_sentiment_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5979de15",
   "metadata": {},
   "source": [
    "### 8. Fine-tune on Manually Labeled WWII Bunker Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80769e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load labeled bunker data (now includes neutral!)\n",
    "df_train = pd.read_pickle(\"../data/processed/bunker_reviews_fine_tuning.pkl\")\n",
    "print(\"Total labeled reviews:\", len(df_train))\n",
    "\n",
    "# 2. Map text labels → integer IDs for all three classes\n",
    "label2id = {\"negative\":0, \"neutral\":1, \"positive\":2}\n",
    "df_train[\"label_id\"] = df_train[\"manual_classification\"].map(label2id)\n",
    "\n",
    "texts  = df_train[\"clean_text\"].tolist()\n",
    "labels = df_train[\"label_id\"].tolist()\n",
    "\n",
    "# 3. Split into train / validation (e.g. 80/20 here)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")\n",
    "print(\" → train:\", len(train_texts), \"  val:\", len(val_texts))\n",
    "\n",
    "# 4. Compute class weights for the 3 classes\n",
    "classes = np.unique(train_labels)\n",
    "weights = compute_class_weight(\"balanced\", classes=classes, y=train_labels)\n",
    "class_weights = torch.tensor(weights, dtype=torch.float)\n",
    "print(\"Class weights:\", dict(zip(classes, weights)))\n",
    "\n",
    "# 5. Dataset wrapper\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text  = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\":      enc[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(),\n",
    "            \"labels\":         torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# 6. Custom Trainer to apply weighted loss\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = CrossEntropyLoss(weight=class_weights.to(model.device))\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# 7. Tokenizer & Datasets\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "train_ds = SentimentDataset(train_texts, train_labels, tokenizer)\n",
    "val_ds   = SentimentDataset(val_texts,   val_labels,   tokenizer)\n",
    "\n",
    "# 8. Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"outputs/bunker_multi_class\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "# 9. Model with 3 output labels\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=3\n",
    ")\n",
    "\n",
    "# 10. Initialize and launch training\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds\n",
    ")\n",
    "\n",
    "print(\"Fine‑tuning three‑way (neg/neu/pos) BERT on bunker data …\")\n",
    "trainer.train()\n",
    "trainer.save_model(\"outputs/bunker_multi_class/final_model\")\n",
    "print(\"Done, model saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f6b6c",
   "metadata": {},
   "source": [
    "### 9. Evaluate on WWII Bunker Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de3d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the 3‑class model you just fine‑tuned\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"outputs/bunker_multi_class/final_model\",\n",
    "    num_labels=3\n",
    ")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# 2. Load your manual test set (with all three labels still present)\n",
    "df_test = pd.read_pickle(\"../data/processed/bunker_reviews_test_set.pkl\")\n",
    "print(f\"Full manual test set: {len(df_test)} reviews\")\n",
    "\n",
    "# Map textual labels → integers\n",
    "label2id = {\"negative\":0, \"neutral\":1, \"positive\":2}\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "df_test[\"label_id\"] = df_test[\"manual_classification\"].map(label2id)\n",
    "\n",
    "# 3. Build a simple inference Dataset\n",
    "class InferenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\":      enc[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze()\n",
    "        }\n",
    "\n",
    "test_texts = df_test[\"clean_text\"].tolist()\n",
    "test_ds    = InferenceDataset(test_texts, tokenizer)\n",
    "\n",
    "# 4. Run predictions\n",
    "trainer = Trainer(model=model, args=TrainingArguments(output_dir=\"tmp_eval\", per_device_eval_batch_size=8))\n",
    "preds_output = trainer.predict(test_ds)\n",
    "logits = preds_output.predictions                     # shape (N,3)\n",
    "probs  = F.softmax(torch.tensor(logits), dim=1).numpy()\n",
    "pred_ids = probs.argmax(axis=1)\n",
    "\n",
    "# 5. Map back to string labels\n",
    "df_test[\"predicted_sentiment\"] = [id2label[i] for i in pred_ids]\n",
    "\n",
    "# 6. Compute metrics\n",
    "y_true = df_test[\"label_id\"].tolist()\n",
    "y_pred = pred_ids.tolist()\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nOverall accuracy: {acc:.4f}\\n\")\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
    "print(pd.DataFrame(cm, index=[\"neg\",\"neu\",\"pos\"], columns=[\"neg\",\"neu\",\"pos\"]))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"negative\",\"neutral\",\"positive\"]))\n",
    "\n",
    "# 7. Inspect the errors\n",
    "errors = df_test[df_test[\"label_id\"] != df_test[\"predicted_sentiment\"].map(label2id)]\n",
    "print(f\"\\nNumber of misclassified examples: {len(errors)}\")\n",
    "display(errors[[\"clean_text\",\"manual_classification\",\"predicted_sentiment\"]].head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
