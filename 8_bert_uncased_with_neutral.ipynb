{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b9e4a1",
   "metadata": {},
   "source": [
    "# Sentiment Classification Model 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff75b4",
   "metadata": {},
   "source": [
    "Trained on merged dataset (SST-3, DynaSent R1, R2) with neutral reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc6ae4d",
   "metadata": {},
   "source": [
    "### 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24964ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from transformers import (\n",
    "    BertTokenizer, \n",
    "    BertForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support, f1_score\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280cfe62",
   "metadata": {},
   "source": [
    "### 2. Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfbe3899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, ClassLabel\n",
    "\n",
    "dataset = load_dataset(\"jbeno/sentiment_merged\")\n",
    "\n",
    "label_names = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "dataset = dataset.cast_column(\"label\", ClassLabel(names=label_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faf42de",
   "metadata": {},
   "source": [
    "### 3. Create a Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56df5453-d2ce-4d71-997f-8b19a00fe2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19d118c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878f50199b8844e899d500c45042bc7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/102097 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36bb85d65b374e4b9e4cd366a16b215b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5421 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4c263fcfaf451f87433429b3fe8f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_batch(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "dataset = dataset.map(tokenize_batch, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee50022",
   "metadata": {},
   "source": [
    "### 4. Instansiate Tokenizer & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03bc571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767e0e2e",
   "metadata": {},
   "source": [
    "### 5. Initialize Model and Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36e6ba8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/askk/.local/lib/python3.10/site-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"outputs_uncased_8\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"logs_uncased\",\n",
    "    logging_steps=50,\n",
    "    fp16=True if torch.cuda.is_available() else False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91600c86",
   "metadata": {},
   "source": [
    "### 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ad60ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46dfd548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3002294/722961556.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"weighted\"\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset= dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff73e210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training bert-base-uncased model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38289' max='38289' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38289/38289 55:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.667300</td>\n",
       "      <td>0.723802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.497500</td>\n",
       "      <td>0.741225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.270500</td>\n",
       "      <td>1.160512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=38289, training_loss=0.49712436580082603, metrics={'train_runtime': 3359.4996, 'train_samples_per_second': 91.172, 'train_steps_per_second': 11.397, 'total_flos': 8.058927182932685e+16, 'train_loss': 0.49712436580082603, 'epoch': 3.0})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training bert-base-uncased model...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b4c175d-7a6e-4157-aeba-db16e372afbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval_accuracy</th>\n",
       "      <td>0.739510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_f1</th>\n",
       "      <td>0.741480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_loss</th>\n",
       "      <td>1.111310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_model_preparation_time</th>\n",
       "      <td>0.024500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_precision</th>\n",
       "      <td>0.749701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_recall</th>\n",
       "      <td>0.739510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_runtime</th>\n",
       "      <td>19.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <td>332.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <td>41.620000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  value\n",
       "metric                                 \n",
       "eval_accuracy                  0.739510\n",
       "eval_f1                        0.741480\n",
       "eval_loss                      1.111310\n",
       "eval_model_preparation_time    0.024500\n",
       "eval_precision                 0.749701\n",
       "eval_recall                    0.739510\n",
       "eval_runtime                  19.630000\n",
       "eval_samples_per_second      332.655000\n",
       "eval_steps_per_second         41.620000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = trainer.evaluate(eval_dataset=dataset[\"test\"])\n",
    "# turn into a 2â€‘column table (metric name + value)\n",
    "df_metrics = (\n",
    "    pd.Series(metrics)\n",
    "      .rename_axis(\"metric\")\n",
    "      .to_frame(\"value\")\n",
    "      .sort_values(by=\"metric\")\n",
    ")\n",
    "display(df_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ab343ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='None' max='38289' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      None\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='817' max='817' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [817/817 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_uncased = trainer_uncased.predict(test_ds_uncased)\n",
    "pred_labels_uncased = predictions_uncased.predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5979de15",
   "metadata": {},
   "source": [
    "### 7. Fine-tune on Manually Labeled WWII Bunker Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d80769e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fineâ€‘tuning threeâ€‘way (neg/neu/pos) BERT on bunker data â€¦\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [234/234 00:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.053400</td>\n",
       "      <td>0.952271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.599400</td>\n",
       "      <td>0.694078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.913246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, model saved.\n"
     ]
    }
   ],
   "source": [
    "# 1) load + labelâ€‘encode\n",
    "df_train = pd.read_pickle(\"../data/processed/bunker_reviews_fine_tuning.pkl\")\n",
    "label2id = {\"negative\":0, \"neutral\":1, \"positive\":2}\n",
    "df_train[\"label_id\"] = df_train[\"manual_classification\"].map(label2id)\n",
    "\n",
    "# drop anything that couldn't be mapped\n",
    "df_train = df_train.dropna(subset=[\"label_id\"])\n",
    "df_train[\"label_id\"] = df_train[\"label_id\"].astype(int)\n",
    "\n",
    "# 2) Split\n",
    "texts  = df_train[\"clean_text\"].tolist()\n",
    "labels = df_train[\"label_id\"].tolist()\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "# 3. Compute perâ€‘class weights\n",
    "classes = np.unique(train_labels)\n",
    "weights = compute_class_weight(\"balanced\", classes=classes, y=train_labels)\n",
    "class_weights = torch.tensor(weights, dtype=torch.float)\n",
    "\n",
    "# 4. Dataset wrapper (as before)\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\":      enc[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(),\n",
    "            \"labels\":         torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# 5. Weighted Trainer\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = CrossEntropyLoss(weight=class_weights.to(model.device))\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# 6. Tokenizer & Datasets\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "train_ds = SentimentDataset(train_texts, train_labels, tokenizer)\n",
    "val_ds   = SentimentDataset(val_texts,   val_labels,   tokenizer)\n",
    "\n",
    "# 7. Training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"outputs/bunker_multi_class\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "# 8. Model & Trainer\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=3\n",
    ")\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds\n",
    ")\n",
    "\n",
    "# 9. Train!\n",
    "print(\"Fineâ€‘tuning threeâ€‘way (neg/neu/pos) BERT on bunker data â€¦\")\n",
    "trainer.train()\n",
    "trainer.save_model(\"outputs/bunker_multi_class/final_model\")\n",
    "print(\"Done, model saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f6b6c",
   "metadata": {},
   "source": [
    "### 8. Evaluate on WWII Bunker Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a6de3d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full manual test set: 194 reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall accuracy: 0.9124\n",
      "\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          negative  neutral  positive\n",
       "negative        12        3         0\n",
       "neutral          2       14         6\n",
       "positive         0        6       151"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.80      0.83        15\n",
      "     neutral       0.61      0.64      0.62        22\n",
      "    positive       0.96      0.96      0.96       157\n",
      "\n",
      "    accuracy                           0.91       194\n",
      "   macro avg       0.81      0.80      0.80       194\n",
      "weighted avg       0.91      0.91      0.91       194\n",
      "\n",
      "\n",
      "Number of misclassified examples: 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>manual_classification</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great ship, only the guide makes it difficult ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I guess it's ok but not really any indication ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>It's okay and you get to see a lot. But this s...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Magic</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Only recommended with a guided tour, as you ca...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Underwater base and pool of lights (idem) Restful</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Super interesting! However, I felt a little un...</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Top!</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Interesting museum in principle and is a histo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Interesting place, too bad I didnâ€™t get inside...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean_text manual_classification  \\\n",
       "4    Great ship, only the guide makes it difficult ...               neutral   \n",
       "8    I guess it's ok but not really any indication ...              negative   \n",
       "35   It's okay and you get to see a lot. But this s...              negative   \n",
       "49                                               Magic              positive   \n",
       "53   Only recommended with a guided tour, as you ca...               neutral   \n",
       "54   Underwater base and pool of lights (idem) Restful               neutral   \n",
       "75   Super interesting! However, I felt a little un...              positive   \n",
       "87                                                Top!              positive   \n",
       "93   Interesting museum in principle and is a histo...              negative   \n",
       "104  Interesting place, too bad I didnâ€™t get inside...               neutral   \n",
       "\n",
       "    predicted_sentiment  \n",
       "4              positive  \n",
       "8               neutral  \n",
       "35              neutral  \n",
       "49              neutral  \n",
       "53             positive  \n",
       "54             positive  \n",
       "75              neutral  \n",
       "87              neutral  \n",
       "93              neutral  \n",
       "104            positive  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All misclassified reviews saved to data/processed/bunker_multi_class_misclassified.csv\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the fineâ€‘tuned 3â€‘way model\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"outputs/bunker_multi_class/final_model\",\n",
    "    num_labels=3\n",
    ")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# 2. Load your manual test set\n",
    "df_test = pd.read_pickle(\"../data/processed/bunker_reviews_test_set.pkl\")\n",
    "print(f\"Full manual test set: {len(df_test)} reviews\")\n",
    "\n",
    "# Create mappings label<->ID\n",
    "label2id = {\"negative\":0, \"neutral\":1, \"positive\":2}\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "\n",
    "# Encode the true labels\n",
    "df_test[\"label_id\"] = df_test[\"manual_classification\"].map(label2id)\n",
    "\n",
    "# 3. Build an inference Dataset\n",
    "class InferenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\":      enc[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze()\n",
    "        }\n",
    "\n",
    "test_texts = df_test[\"clean_text\"].tolist()\n",
    "test_ds    = InferenceDataset(test_texts, tokenizer)\n",
    "\n",
    "# 4. Run predictions\n",
    "eval_args = TrainingArguments(\n",
    "    output_dir=\"tmp_eval\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    dataloader_drop_last=False,\n",
    ")\n",
    "trainer = Trainer(model=model, args=eval_args)\n",
    "preds_output = trainer.predict(test_ds)\n",
    "logits = preds_output.predictions           # shape (N, 3)\n",
    "probs  = F.softmax(torch.tensor(logits), dim=1).numpy()\n",
    "pred_ids = probs.argmax(axis=1)\n",
    "\n",
    "# 5. Map back to string labels\n",
    "df_test[\"predicted_sentiment\"] = [id2label[i] for i in pred_ids]\n",
    "\n",
    "# 6. Compute metrics\n",
    "y_true = df_test[\"label_id\"].tolist()\n",
    "y_pred = pred_ids.tolist()\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nOverall accuracy: {acc:.4f}\\n\")\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index=[\"negative\",\"neutral\",\"positive\"],\n",
    "                     columns=[\"negative\",\"neutral\",\"positive\"])\n",
    "display(cm_df)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred,\n",
    "                            target_names=[\"negative\",\"neutral\",\"positive\"]))\n",
    "\n",
    "# 7. Inspect a few of the misclassified reviews\n",
    "errors = df_test[df_test[\"label_id\"] != df_test[\"predicted_sentiment\"].map(label2id)]\n",
    "print(f\"\\nNumber of misclassified examples: {len(errors)}\")\n",
    "display(errors[[\"clean_text\",\"manual_classification\",\"predicted_sentiment\"]].head(10))\n",
    "\n",
    "# 8. Save all misclassified reviews to disk\n",
    "errors.to_csv(\"../data/processed/bunker_multi_class_misclassified.csv\", \n",
    "              columns=[\"clean_text\",\"manual_classification\",\"predicted_sentiment\"], \n",
    "              index=False)\n",
    "print(\"All misclassified reviews saved to data/processed/bunker_multi_class_misclassified.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165b1b1f-b520-41ac-8a40-d4817509b854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
